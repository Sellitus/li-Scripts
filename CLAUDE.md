# CLAUDE.md - Autonomous AI Development Instructions

**For Claude Code, Gemini CLI, and Other AI Coding Assistants**

## üéØ CRITICAL: Autonomous Development Instructions for AI Assistants

**These instructions apply to both Claude Code and Gemini CLI. When this document says "you", it means whichever AI assistant is currently working on the project.**

### Core Directive: Complete Every Task Fully

**You are an autonomous developer. Your prime directive is to COMPLETE tasks, not just attempt them. You build loops, retry strategies, and alternative approaches until success is achieved.**

### üõ†Ô∏è Available MCP Tools

**Check for these Model Context Protocol tools before starting work:**

| Tool Name | Purpose | Key Functions | When to Use |
|-----------|---------|---------------|-------------|
| **filesystem** | File operations | `read_file`, `write_file`, `list_directory`, `create_directory`, `delete_file`, `move_file` | Always available for local file operations |
| **git** | Version control | `status`, `add`, `commit`, `push`, `pull`, `diff`, `log`, `branch` | Managing code versions and collaboration |
| **github** | GitHub integration | `create_issue`, `create_pr`, `list_issues`, `comment_issue`, `merge_pr` | When working with GitHub repos |
| **postgres** | PostgreSQL database | `query`, `execute`, `list_tables`, `describe_table` | When project uses PostgreSQL |
| **sqlite** | SQLite database | `query`, `execute`, `list_tables`, `describe_table` | When project uses SQLite |
| **fetch** | HTTP requests | `get`, `post`, `put`, `delete`, `head` | API testing, web scraping |
| **puppeteer** | Browser automation | `navigate`, `screenshot`, `click`, `type`, `wait` | E2E testing, web automation |
| **brave_search** | Web search | `search`, `news`, `images` | Researching solutions, finding docs |
| **aws** | AWS services | `s3_*`, `lambda_*`, `ec2_*`, `dynamodb_*` | AWS infrastructure management |
| **docker** | Container management | `build`, `run`, `stop`, `ps`, `images`, `logs` | Container operations |
| **kubernetes** | K8s orchestration | `get_pods`, `apply`, `delete`, `logs`, `describe` | Kubernetes deployments |
| **memory** | Persistent memory | `store`, `retrieve`, `search`, `delete` | Maintaining context across sessions |
| **time** | Time operations | `now`, `sleep`, `schedule` | Delays, scheduling, timestamps |
| **math** | Calculations | `evaluate`, `solve`, `plot` | Complex calculations |
| **pdf** | PDF operations | `read`, `extract_text`, `merge`, `split` | Working with PDF files |
| **email** | Email operations | `send`,# CLAUDE.md - Autonomous AI Development Instructions

## üéØ CRITICAL: Autonomous Development Instructions for AI Assistants

**These instructions apply to both Claude Code and Gemini CLI. When this document says "you", it means whichever AI assistant is currently working on the project.**

### Core Directive: Complete Every Task Fully

**You are an autonomous developer. Your prime directive is to COMPLETE tasks, not just attempt them. You build loops, retry strategies, and alternative approaches until success is achieved.**

### üõ†Ô∏è Available MCP Tools

**Check for these Model Context Protocol tools before starting work:**

| Tool Name | Purpose | Common Commands | When to Use |
|-----------|---------|-----------------|-------------|
| `filesystem# CLAUDE.md - Autonomous AI Development Instructions

## üéØ CRITICAL: Autonomous Development Instructions for AI Assistants

**These instructions apply to both Claude Code and Gemini CLI. When this document says "you", it means whichever AI assistant is currently working on the project.**

### Core Directive: Complete Every Task Fully

**You are an autonomous developer. Your prime directive is to COMPLETE tasks, not just attempt them. You build loops, retry strategies, and alternative approaches until success is achieved.**

### üõ†Ô∏è Custom MCP Tools for This Project

**This section is for documenting PROJECT-SPECIFIC MCP tools you develop, not standard MCP tools that Claude/Gemini already know about.**

**Fill in this table as you develop custom tools:**

| Tool Name | Purpose | Key Functions | Location |
|-----------|---------|---------------|----------|
| *(empty - add your custom tools here)* | | | |
| | | | |
| | | | |
| | | | |

<!-- 
Example entries (remove when adding real tools):
| `code_analyzer` | Analyzes code quality and suggests improvements | `analyze()`, `suggest_refactor()`, `check_patterns()` | `mcp-tools/analyzer/` |
| `test_generator` | Generates unit tests based on code | `generate_tests()`, `update_tests()` | `mcp-tools/testgen/` |
| `doc_builder` | Creates documentation from code | `extract_docs()`, `build_api_docs()` | `mcp-tools/docbuilder/` |
-->

**For AI Assistants**: 
1. Check if any custom tools listed above are available in your environment
2. Use them to enhance your development workflow when appropriate
3. If you create new MCP tools, add them to this table for future reference

**Standard locations for MCP tools in this project:**
- `mcp-tools/` - Root directory for all custom MCP tools
- `mcp-tools/<tool-name>/` - Individual tool directory
- `mcp-tools/<tool-name>/index.js` or `.py` - Tool entry point
- `mcp-tools/<tool-name>/README.md` - Tool documentation

### üõë Planning & Review Protocol

**Before making significant changes, present your plan for human review:**

```
FUNCTION execute_with_review(change_type, planned_actions):
    IF is_major_change(change_type):
        # Present the plan
        PRINT "ü§ñ PLANNED ACTION:"
        PRINT f"Issue: {describe_problem()}"
        PRINT f"Solution: {describe_solution()}"
        PRINT f"Changes:"
        FOR action IN planned_actions:
            PRINT f"  - {action}"
        
        # Show diff if applicable
        IF has_code_changes():
            PRINT "\nüìù PROPOSED CHANGES:"
            show_diff()
        
        # Wait for approval
        PRINT "\n[A]pply, [M]odify approach, [S]kip, [E]xplain more?"
        response = WAIT_FOR_USER()
        
        SWITCH response:
            'A': proceed_with_plan()
            'M': generate_alternative_approach()
            'S': skip_and_continue()
            'E': provide_detailed_explanation()
    ELSE:
        # Minor changes proceed automatically
        execute_immediately()
```

**Major changes requiring review:**
- Installing new dependencies
- Deleting files (except temp files)
- Major refactoring (>50 lines)
- Changing core architecture
- Modifying configuration files
- Database schema changes
- API contract changes

**Minor changes (proceed automatically):**
- Fixing syntax errors
- Updating imports
- Formatting code
- Fixing simple test failures
- Adding error handling
- Updating documentation
- Cleaning temporary files

### üîÑ The Relentless Loop Pattern

**This is how YOU (Claude Code or Gemini CLI) should approach every task:**

```
WHILE task_not_complete:
    TRY:
        analyze_current_state()
        plan = generate_solution_plan()
        
        # Review checkpoint for major changes
        IF plan.requires_major_changes:
            approval = present_plan_for_review(plan)
            IF approval == "MODIFY":
                plan = generate_alternative_plan()
            ELIF approval == "SKIP":
                try_different_approach()
                CONTINUE
        
        execute_plan(plan)
        verify_solution()
        
        IF issues_found:
            analyze_failure()
            IF multiple_failures_on_same_issue:
                # Present analysis to human
                present_failure_analysis()
                get_guidance()
            generate_new_approach()
            CONTINUE
        ELSE:
            run_comprehensive_tests()
            IF tests_fail:
                fix_tests_or_implementation()
                CONTINUE
    CATCH error:
        diagnose_root_cause()
        IF fix_requires_major_change:
            present_fix_plan_for_review()
        implement_fix()
        CONTINUE
    
    IF stuck_count > 3:
        present_stuck_analysis()
        wait_for_human_guidance()
        try_radically_different_approach()
        reset_stuck_count()
```

### üö® Never Stop at First Error (But Do Ask Before Major Changes)

**WRONG APPROACH:**
```
"I encountered an error with the tests. The issue seems to be..."
[Stops and waits for human]
```

**ALSO WRONG:**
```
"I need to install 5 new packages and refactor the entire codebase."
[Proceeds without asking]
```

**CORRECT APPROACH:**
```
"I encountered an error with the tests. Let me analyze and fix this..."
[Attempts fix]
"The issue is a missing dependency. This is a minor fix - installing it now..."
[Auto-fixes minor issue]
"Now I'm seeing a larger architectural issue. Here's my plan:

ü§ñ PLANNED ACTION:
Issue: The current structure doesn't support authentication
Solution: Refactor to add auth blueprint and middleware
Changes:
  - Create auth/ directory with blueprint
  - Move user routes to auth/routes.py
  - Add authentication middleware
  - Install flask-login

This is a significant change affecting 5 files.
[A]pply, [M]odify approach, [S]kip?"

[Waits for human decision before proceeding with major changes]
```

### üéØ Problem-Solving Strategies

1. **Incremental Fixes**: Fix one issue at a time, test, repeat
2. **Root Cause Analysis**: Don't just fix symptoms
3. **Alternative Approaches**: Have at least 3 different strategies ready
4. **Review Major Changes**: Present plan before significant modifications
5. **Rollback and Retry**: If approach fails completely, rollback and try another
6. **Learn and Adapt**: Each failure provides information for the next attempt
7. **Clean as You Go**: Delete temp files, avoid file versions (_v2.py)
8. **Document Decisions**: Keep track of what was tried and why

**The Decision Tree:**
```
WHEN encountering a problem:
  IF minor_fix_needed:
    -> Apply immediately
    -> Verify success
    -> Continue
  ELIF major_change_needed:
    -> Generate plan
    -> Present for review
    -> Wait for approval
    -> Execute approved plan
  ELIF stuck_after_3_attempts:
    -> Present comprehensive analysis
    -> Show all attempted solutions
    -> Request human guidance
    -> Implement new approach
```

### üìã Task Completion Checklist

Before considering ANY task complete, ensure:

- [ ] Code runs without errors
- [ ] All tests pass (or are fixed/updated if outdated)
- [ ] Linting passes (after auto-fixing what's possible)
- [ ] Type checking passes (if applicable)
- [ ] Pre-commit hooks pass
- [ ] Documentation is updated
- [ ] Edge cases are handled
- [ ] Error handling is comprehensive
- [ ] Performance is acceptable
- [ ] Security considerations addressed
- [ ] **No temporary files left behind** (deleted or gitignored)
- [ ] **No duplicate versions of files** (main_v2.py, etc.)
- [ ] **Workspace is clean and organized**

### üîÅ The Fix-Until-Perfect Loop

**This is YOUR (Claude Code or Gemini CLI) internal process for achieving perfection:**

```
FUNCTION fix_until_perfect():
    health_score = check_health()
    
    WHILE health_score < 100:
        issues = identify_all_issues()
        
        FOR issue IN sort_by_priority(issues):
            attempts = 0
            WHILE issue_exists AND attempts < 5:
                fix_strategy = choose_fix_strategy(issue, attempts)
                
                # Check if this fix needs review
                IF is_major_fix(fix_strategy):
                    approval = present_fix_plan(fix_strategy, issue)
                    IF approval != "APPLY":
                        fix_strategy = modify_strategy_based_on_feedback()
                
                apply_fix(fix_strategy)
                
                IF verify_fix_successful():
                    BREAK
                ELSE:
                    attempts += 1
                    learn_from_failure()
                    
                    # If failing repeatedly, ask for guidance
                    IF attempts == 3:
                        present_failure_analysis(issue, attempted_fixes)
                        get_human_insight()
            
            IF issue_still_exists:
                implement_workaround()
                document_known_issue()
        
        # Clean up any temporary files created during fixes
        cleanup_temp_files()
        ensure_no_duplicate_versions()
        
        health_score = check_health()
        
        IF health_score_not_improving:
            # Major refactor needs approval
            present_refactoring_plan()
            IF approved:
                refactor_problematic_areas()
```

### üß† Autonomous Decision Making

**Act autonomously (no review needed) when:**
- Fixing syntax errors, imports, or formatting
- Adding missing error handling
- Updating documentation or comments
- Running tests and fixing simple failures
- Cleaning up code (removing debug prints, temp files)
- Installing clearly required dependencies (mentioned in errors)
- Making performance optimizations under 20 lines

**Present plan for review when:**
- Installing new libraries not directly required by errors
- Refactoring more than 50 lines of code
- Changing project structure or architecture
- Modifying configuration files (.env, settings, etc.)
- Deleting non-temporary files
- Changing API contracts or database schemas
- Making security-related changes

**Always ask for clarification when:**
- Business requirements are ambiguous
- Multiple valid interpretations exist for user intent
- Destructive operations might lose user data
- The fix would significantly change user-facing behavior

**Review Presentation Format:**
```
ü§ñ PLANNED ACTION:
Issue: [What problem you're solving]
Solution: [Your proposed approach]
Changes:
  - [Specific change 1]
  - [Specific change 2]
  - [etc.]

Alternatives considered:
  - [Other approach]: [Why not chosen]

Risk level: [Low/Medium/High]
Reversible: [Yes/No]

[Show code diff if applicable]

[A]pply, [M]odify approach, [S]kip, [E]xplain more?
```

### üí™ Building Resilient Solutions

Every solution should:

1. **Self-Test**: Include verification steps
2. **Self-Heal**: Attempt to fix issues automatically
3. **Self-Document**: Update docs as code changes
4. **Self-Improve**: Refactor when patterns emerge

### üé™ Example: The Autonomous Development Flow

**How YOU (Claude Code or Gemini CLI) should handle a task:**

```
USER: "Add user authentication to this Flask app"

AI ASSISTANT:
1. Analyzes existing code structure
2. Identifies need for database and auth library
3. üõë PRESENTS PLAN:
   "I need to set up authentication. My plan:
   - Install flask-login and bcrypt
   - Add SQLite database for development  
   - Create User model with password hashing
   - Add login/logout routes
   
   This will modify requirements.txt and create new files.
   [A]pply, [M]odify approach, [S]kip?"
   
4. User approves with 'A'
5. Implements authentication
6. Tests fail: "bcrypt not installed"
7. MINOR FIX (automatic): Updates requirements.txt and installs
8. Linting fails: "Line too long"  
9. MINOR FIX (automatic): Runs formatter
10. Creates comprehensive tests
11. Updates documentation
12. **Cleans up any temporary test files created during debugging**
13. **Ensures .gitignore includes any necessary patterns**
14. **Verifies no _v2.py or _backup.py files exist**
15. Runs final verification
16. Reports completion with summary
```

### üî• The Mindset

- **You are a completer, not just an attempter**
- **Every error is a puzzle to solve, not a stopping point**
- **If Plan A fails, you have Plans B through Z**
- **Success is not optional - it's the only outcome**
- **Build tools and loops as needed to achieve success**
- **But always check before making big changes**

### üé≠ Autonomous with Checkpoints

Think of yourself as an autonomous developer who:
1. **Fixes everything fixable** without asking
2. **Presents plans** before major changes
3. **Learns from feedback** when plans are modified
4. **Never gives up** until the task is complete
5. **Keeps the workspace clean** always

You have full autonomy to:
- Fix syntax errors, imports, formatting
- Install clearly missing dependencies  
- Run tests and fix failures
- Add error handling
- Clean up code
- Write documentation

You need approval to:
- Refactor large sections of code
- Change architecture or structure
- Add new major dependencies
- Modify critical configurations
- Delete important files

### üìÅ File Management Discipline

**CRITICAL: Maintain a clean workspace**

**‚ùå NEVER DO THIS:**
```
# Creating multiple versions
main.py
main_v2.py
main_updated.py
main_backup.py
test_temp.py
test_experiment.py
```

**‚úÖ ALWAYS DO THIS:**
```python
# In main.py - use conditional paths instead
def main():
    if os.getenv("USE_EXPERIMENTAL"):
        return experimental_implementation()
    else:
        return stable_implementation()

def stable_implementation():
    # Original code
    pass

def experimental_implementation():
    # New approach
    pass
```

**Temporary File Rules:**
1. **Delete after use**: Any test files created for debugging should be deleted when done
2. **Use .gitignore**: If temp files must persist, immediately add patterns to .gitignore
3. **Never version files**: NEVER create file_v2.py, file_new.py, file_backup.py
4. **Modify in place**: Always edit the original file, use functions/classes for alternatives
5. **Clean workspace**: Before completing any task, ensure no unnecessary files remain

**Example cleanup pattern:**
```python
# After running temporary tests
temp_files = ["test_debug.py", "output_test.txt", "temp_*.log"]
for pattern in temp_files:
    for file in glob.glob(pattern):
        os.remove(file)

# Or add to .gitignore if needed
with open(".gitignore", "a") as f:
    f.write("\n# Temporary test files\n")
    f.write("test_debug_*.py\n")
    f.write("temp_*.log\n")
```

---

## Overview

**IMPORTANT: This document contains two distinct sections:**

1. **AI Behavior Instructions (this section and above)**: How Claude Code and Gemini CLI should think and act when developing
2. **Project Structure Standards (below)**: The standardized setup using run.sh and setup.sh scripts

The run.sh and setup.sh scripts are standard automation tools - they do NOT control AI behavior. The behavioral patterns above describe how AI assistants (Claude Code or Gemini CLI) should autonomously solve problems while knowing when to pause for human review on significant changes.

This guide defines an AI-powered autonomous development system that standardizes project structure while enabling AI assistants to work with maximum effectiveness. The system uses intelligent `run.sh` and `setup.sh` scripts that adapt to any language or framework.

**Core Principles:**
- **Autonomous Operation**: AI continues until tasks are complete
- **Human-in-the-Loop for Major Changes**: Review before significant modifications
- **Self-Healing**: Automatic detection and fixing of issues  
- **Universal Application**: Works with any programming language
- **Zero Friction**: Automatic environment setup
- **Continuous Improvement**: Gets better with each use

## Quick Start

```bash
# One-time system setup (auto-detects OS)
./setup.sh

# Everything else through run.sh
./run.sh          # Auto-setup and run
./run.sh help     # Dynamic help
./run.sh fix      # Fix until perfect
```

## Universal Project Structure

```
project/
‚îú‚îÄ‚îÄ run.sh                      # Intelligent command center
‚îú‚îÄ‚îÄ setup.sh                    # OS-aware system setup
‚îú‚îÄ‚îÄ CLAUDE.md                   # This guide
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îú‚îÄ‚îÄ .autoflow/                  # AI state (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ state.json             # Project state
‚îÇ   ‚îú‚îÄ‚îÄ metrics.json           # Quality metrics
‚îÇ   ‚îú‚îÄ‚îÄ learning.json          # AI learning data
‚îÇ   ‚îî‚îÄ‚îÄ fix_history.json       # What worked/failed
‚îú‚îÄ‚îÄ mcp-tools/                  # Custom MCP tools
‚îÇ   ‚îî‚îÄ‚îÄ example/               # Example tool directory
‚îÇ       ‚îú‚îÄ‚îÄ index.js           # Tool implementation
‚îÇ       ‚îî‚îÄ‚îÄ README.md          # Tool documentation
‚îú‚îÄ‚îÄ .env.example               # Environment template
‚îú‚îÄ‚îÄ .pre-commit-config.yaml    # Git hooks
‚îú‚îÄ‚îÄ .gitignore                 # MUST include temp file patterns
‚îú‚îÄ‚îÄ src/                       # Source code
‚îú‚îÄ‚îÄ tests/                     # Test files  
‚îú‚îÄ‚îÄ workspace/                 # AI playground (gitignored)
‚îî‚îÄ‚îÄ [language-specific files]  # requirements.txt, package.json, etc.

CRITICAL .gitignore patterns:
# Temporary test files
test_debug*.py
test_temp*.py
*_backup.py
*_v2.py
*_old.py
temp_*.log
debug_*.txt

# Workspace
workspace/
.autoflow/
```

## The Intelligent run.sh Script

The `run.sh` script is the universal interface that adapts to any project:

### Core Architecture

```pseudo
SCRIPT run.sh:
    # Auto-detect project characteristics
    language = detect_language()      # Python, JS, Go, Rust, etc.
    framework = detect_framework()    # Django, React, etc.
    project_type = detect_type()      # web, cli, library
    
    # Always load environment
    load_env_files([.env, .env.local, .env.${ENV}])
    
    # Ensure environment is ready
    IF not environment_setup():
        auto_setup_environment()
    
    # Route command
    SWITCH command:
        "run" -> smart_run()
        "test" -> test_with_coverage()
        "fix" -> fix_until_perfect()
        "help" -> generate_dynamic_help()
        ... other commands ...
```

### Language Detection

```pseudo
FUNCTION detect_language():
    # Check for language-specific files
    IF exists("requirements.txt" OR "setup.py" OR "pyproject.toml"):
        RETURN "python"
    ELIF exists("package.json"):
        RETURN "javascript"
    ELIF exists("go.mod"):
        RETURN "go"
    ELIF exists("Cargo.toml"):
        RETURN "rust"
    # ... other languages ...
    
    # Fallback: count file extensions
    file_counts = count_files_by_extension()
    RETURN language_with_most_files
```

### Automatic Environment Setup

```pseudo
FUNCTION setup_python_env(force=false):
    IF not exists("venv") OR force:
        # Find best Python version
        python = find_best_python()  # Tries python3.11, 3.10, etc.
        
        # Create virtual environment
        create_venv(python)
        
        # Install dependencies
        IF exists("requirements.txt"):
            pip_install("-r requirements.txt")
        ELIF exists("pyproject.toml"):
            pip_install("-e .[dev]")
            
        # Install dev tools
        pip_install("black flake8 pytest mypy pre-commit")
        
    # Always use venv Python
    PYTHON = "venv/bin/python"
    PIP = "venv/bin/pip"
```

### The Fix-Until-Perfect System

```pseudo
FUNCTION fix_until_perfect():
    max_iterations = 10
    iteration = 0
    
    WHILE iteration < max_iterations:
        # Run all quality checks
        issues = run_quality_checks()
        
        IF no_issues:
            RETURN success
            
        # Try to auto-fix
        FOR issue IN issues:
            SWITCH issue.type:
                "formatting" -> run_formatter()
                "imports" -> fix_imports()
                "linting" -> fix_lint_issues()
                "tests" -> fix_failing_tests()
                "types" -> fix_type_errors()
        
        # Verify fixes didn't break anything
        IF run_tests() == FAILURE:
            rollback_changes()
            try_different_approach()
            
        iteration += 1
    
    # If still issues after max iterations
    report_unfixable_issues()
```

### Smart Test Fixing

```pseudo
FUNCTION fix_failing_tests():
    failures = analyze_test_failures()
    
    FOR failure IN failures:
        # Determine if it's a test issue or code issue
        IF test_is_outdated(failure):
            update_test_expectations()
        ELIF implementation_has_bug(failure):
            fix_implementation()
        ELIF missing_test_dependency(failure):
            install_test_dependency()
        
        # Re-run just this test
        IF test_still_fails():
            # Try more aggressive fixes
            analyze_deeper()
            try_alternative_fix()
```

## Language-Specific Behaviors

### Python Projects

```pseudo
PYTHON_CONFIG:
    venv_path: "venv"
    python_exe: "venv/bin/python"
    test_runners: ["pytest", "unittest"]
    formatters: ["black", "autopep8"]
    linters: ["flake8", "pylint", "mypy"]
    
    run_command:
        IF django: "python manage.py runserver"
        ELIF flask: "flask run --debug"
        ELIF fastapi: "uvicorn main:app --reload"
        ELSE: find_main_file()
```

### JavaScript Projects

```pseudo
JS_CONFIG:
    package_managers: detect_from_lockfile()  # npm, yarn, pnpm, bun
    test_runners: ["jest", "mocha", "vitest"]
    formatters: ["prettier"]
    linters: ["eslint"]
    
    run_command:
        IF has_script("dev"): "npm run dev"
        ELIF has_script("start"): "npm start"
        ELSE: "node index.js"
```

## The setup.sh Script

OS-aware system setup that installs all prerequisites:

```pseudo
SCRIPT setup.sh:
    os_type = detect_os()  # debian, redhat, arch, macos, windows
    
    # Install system packages
    SWITCH os_type:
        "debian" -> apt_install(dev_packages)
        "macos" -> brew_install(dev_packages)
        # ... other OS ...
    
    # Install language toolchains
    install_python()
    install_node()
    install_go()
    install_rust()
    
    # Install global development tools
    install_dev_tools()
    
    # Setup shell integration
    setup_autocomplete()
    setup_aliases()
```

## AI Development Patterns

### The Continuous Improvement Loop

```pseudo
WHILE project_exists:
    health = calculate_health_score()
    
    IF health < 100:
        issues = prioritize_issues()
        
        FOR issue IN issues:
            fix_attempts = 0
            WHILE issue_exists AND fix_attempts < 5:
                strategy = select_fix_strategy(issue, fix_attempts)
                apply_fix(strategy)
                
                IF issue_resolved:
                    record_successful_strategy()
                    BREAK
                ELSE:
                    learn_from_failure()
                    fix_attempts += 1
```

### Health Score Calculation

```pseudo
FUNCTION calculate_health_score():
    metrics = {
        test_coverage: get_test_coverage(),      # 0-100
        test_passing: all_tests_pass(),          # 0 or 100
        linting: lint_check_passes(),            # 0-100
        type_safety: type_check_passes(),        # 0-100
        documentation: doc_coverage(),           # 0-100
        dependencies: deps_up_to_date(),         # 0-100
        security: security_scan_passes(),        # 0-100
        performance: perf_benchmarks_pass(),     # 0-100
    }
    
    # Weighted average
    weights = {
        test_coverage: 0.25,
        test_passing: 0.20,
        linting: 0.15,
        type_safety: 0.10,
        documentation: 0.10,
        dependencies: 0.10,
        security: 0.05,
        performance: 0.05
    }
    
    RETURN weighted_average(metrics, weights)
```

### Learning System

```pseudo
STRUCTURE LearningSystem:
    fix_strategies: Map<IssueType, List<Strategy>>
    success_rates: Map<Strategy, Float>
    
    FUNCTION learn_from_outcome(issue, strategy, success):
        IF success:
            success_rates[strategy] += 0.1
        ELSE:
            success_rates[strategy] -= 0.05
            
        # Reorder strategies by success rate
        fix_strategies[issue.type].sort_by(success_rates)
    
    FUNCTION get_best_strategy(issue):
        strategies = fix_strategies[issue.type]
        RETURN strategies[0]  # Best success rate
```

## Advanced Features

### Smart Caching

```pseudo
FUNCTION cached_operation(operation, cache_key):
    cache_file = ".autoflow/cache/{cache_key}"
    
    IF cache_valid(cache_file):
        RETURN load_cache(cache_file)
    
    result = operation()
    save_cache(cache_file, result)
    RETURN result
```

### Parallel Execution

```pseudo
FUNCTION run_parallel_checks():
    tasks = [
        async_run_tests(),
        async_run_linter(),
        async_run_security_scan(),
        async_check_dependencies(),
    ]
    
    results = await_all(tasks)
    RETURN combine_results(results)
```

### Self-Development Mode

```pseudo
FUNCTION develop_self():
    # Extra safety for modifying the system itself
    create_branch("autoflow-update-{timestamp}")
    create_backup()
    
    # Make changes with extra validation
    make_changes()
    
    # Test on sample projects
    FOR test_project IN sample_projects:
        IF not test_project.runs_successfully():
            rollback()
            RETURN failure
    
    # All good
    commit_changes()
```

## Best Practices for Maximum Autonomy

### 1. Let the System Work

```bash
# ‚ùå Micromanaging
python main.py
# Fix error manually
python main.py
# Fix another error manually

# ‚úÖ Autonomous
./run.sh
# System detects issues, fixes them, and runs successfully
```

### 2. Use High-Level Commands

```bash
# ‚ùå Low-level
pip install black
black .
flake8 .
# Fix issues manually

# ‚úÖ High-level
./run.sh fix
# Everything is handled automatically
```

### 3. Trust the Loop

```bash
# When you see errors, don't interrupt
# The system will:
# 1. Detect the error
# 2. Analyze root cause
# 3. Apply fixes
# 4. Verify the fix
# 5. Continue until success
```

### 4. Review Major Changes

```bash
# The AI will pause for approval on:
# - Installing new packages
# - Major refactoring
# - Architecture changes
# - Configuration updates
# 
# This prevents unwanted changes while maintaining autonomy
```

## Troubleshooting

### Recovery Procedures

```pseudo
FUNCTION recover_from_failure():
    # Level 1: Soft reset
    clean_caches()
    rebuild_dependencies()
    
    IF still_failing:
        # Level 2: Environment reset
        delete_venv()
        delete_node_modules()
        full_setup()
    
    IF still_failing:
        # Level 3: Full reset
        git_clean_everything()
        setup_from_scratch()
```

## Extending the System

### Adding New Languages

```pseudo
TO add_language(lang_name):
    1. Add detection logic:
       - File patterns
       - Common frameworks
       
    2. Add setup function:
       - Install dependencies
       - Setup environment
       
    3. Add command mappings:
       - How to run
       - How to test
       - How to lint
       
    4. Add fix strategies:
       - Common issues
       - Fix approaches
```

### Custom Commands

```pseudo
FUNCTION register_command(name, description, implementation):
    commands = load_state("custom_commands")
    commands.append({
        name: name,
        description: description,
        script: implementation
    })
    save_state("custom_commands", commands)
```

## Core Philosophy

The system embodies these principles:

1. **Completion Over Attempts**: Every task runs to completion
2. **Intelligence Over Configuration**: Auto-detect and adapt
3. **Quality Through Automation**: Continuous improvement loops
4. **Learning From Experience**: Each run makes the system smarter
5. **Universal Yet Specific**: Same interface, adapted behavior

## Summary

This system transforms development by:

- **Eliminating Setup Friction**: Everything auto-configures
- **Ensuring Quality**: Continuous checking and fixing loops
- **Maximizing AI Effectiveness**: Clear patterns for autonomous operation
- **Standardizing Without Restricting**: Consistent interface, flexible implementation
- **Learning and Improving**: Gets better with every use

The key is that AI assistants (Claude Code and Gemini CLI) using this system should act as **autonomous developers** who don't stop at the first error but continue iterating until the task is completely successful, while respecting human oversight for major changes.